{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDA  & Scalogram STA 237 Project [Time Series Anomaly Detection Using Computer Vision]",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ormorteey/STA-237-Time-Series/blob/main/EDA_%26_Scalogram_STA_237_Project_%5BTime_Series_Anomaly_Detection_Using_Computer_Vision%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import pywt\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT8xfUPrC4oA"
      },
      "source": [
        "%load_ext rpy2.ipython"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44Yq6iS5_DqF"
      },
      "source": [
        "%%capture\n",
        "%%R\n",
        "# Signify cell is an R cell\n",
        "# Silence Output\n",
        "\n",
        "h = install.packages(\"pacman\")\n",
        "h = library(pacman)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6s1dfIhFDNdf"
      },
      "source": [
        "%%R\n",
        "# load packages for data manipulation in R\n",
        "p_load(\"tidyverse\", \"googledrive\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgcoci3oC3qt"
      },
      "source": [
        "# Silence Output\n",
        "%%capture\n",
        "%%R\n",
        "\n",
        "# killing auth request\n",
        "drive_deauth()\n",
        "drive_user()\n",
        "\n",
        "# retrieving fulll url ID of files\n",
        "public_file = drive_get(as_id(c(\"10i8tM37aqHvD-YH2JK1qZAXzYdawIsgh\",\"1eJ4uXiFqGqsXJ2ut5vex_Lg3BLlUAPjT\",\"1B6pbF90ryhJ-kpu0nQ3FKt6RcSavgCMS\")) )\n",
        "\n",
        "# download the files\n",
        "save_output = 1:3 %>% map(~drive_download(public_file[.,], overwrite = T))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHtEHnrFD8tY"
      },
      "source": [
        "# pulls brian's repo to see latest content from brian\n",
        "!rm -r /content/time-series-image-embedding/\n",
        "!git clone https://github.com/briancknight/time-series-image-embedding.git\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdE_zlEHmN_k"
      },
      "source": [
        "# file location for HDF5 & csv datasets\n",
        "airbus_train_path = 'dftrain.h5'\n",
        "airbus_valid_path = 'dfvalid.h5'\n",
        "airbus_valid_groundtruth_path = 'dfvalid_groundtruth.csv'\n",
        "# read hdf files: training data and validation data and ground truth [labels]\n",
        "train_df = pd.read_hdf(airbus_train_path)\n",
        "valid_df = pd.read_hdf(airbus_valid_path)\n",
        "valid_groundtruth_df = pd.read_csv(airbus_valid_groundtruth_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbK0afAN-Wa1"
      },
      "source": [
        "# Data loading validation & shape check\n",
        "print(valid_groundtruth_df.head())\n",
        "print(train_df.head())\n",
        "print(valid_df.tail())\n",
        "print(valid_groundtruth_df.shape)\n",
        "print(train_df.shape)\n",
        "print(valid_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPiUgqWENpDP"
      },
      "source": [
        "def prepare_dataset(df, rows = 10, cols = 10):\n",
        "  \n",
        "  # cast df as numpy array\n",
        "  df_tensor = df.to_numpy()\n",
        "  # reshape df to tensor to rows of df with 120 series with length 512\n",
        "  df_tensor = np.reshape(df_tensor, (df.shape[0],120, 512))\n",
        "  # diagnostics: shape of dataframe\n",
        "  print(df.shape)\n",
        "  # diagnostics: shape of df tensor\n",
        "  print(df_tensor.shape)\n",
        "  # get continuous wavelet transform scales\n",
        "  SC_scales = np.array([2**(i/4) for i in range(1,65)])\n",
        "\n",
        "  print(SC_scales.shape)\n",
        "\n",
        "  # create empty scalograms\n",
        "  df_scalograms = np.empty([rows, cols, 64, 512])\n",
        "  # fill up scalogram\n",
        "  for ii in np.arange(rows):\n",
        "    for jj in np.arange(cols):\n",
        "      df_scalograms[ii,jj,:,:] =  get_scalogram(df_tensor[ii,jj], SC_scales)\n",
        "  reshape_list = df_scalograms.shape\n",
        "  print(df_scalograms.shape)\n",
        "  df_scalograms = df_scalograms.reshape(reshape_list[0] * reshape_list[1], reshape_list[2], reshape_list[3])\n",
        "\n",
        "  return(df_scalograms)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7jP5hEdWLLY"
      },
      "source": [
        "def get_scalogram(x, SC_scales):\n",
        "  cwtmatr, freqs = pywt.cwt(x, SC_scales, 'mexh')\n",
        "  return(cwtmatr)\n",
        "\n",
        "def scalogram_plotter(x, show = False):\n",
        "  plt.imshow(x, cmap = \"jet\", aspect = \"auto\")\n",
        "  if show == True:\n",
        "      plt.show()\n",
        "\n",
        "def prepare_labels(label_Arr, rows = None, cols = None ):\n",
        "\n",
        "  label_Arr = label_Arr.reshape([rows, 1])\n",
        "  label_Arr = label_Arr.reshape([rows, 1])\n",
        "  label_tensor = np.tile(label_Arr, cols).reshape([rows * cols, 1])\n",
        "  return(label_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpYlZTmmU-R1"
      },
      "source": [
        "# takes approximately 5 minutes for compute\n",
        "\n",
        "rows, cols = 20, 10\n",
        "validation_examples = prepare_dataset(valid_df, rows, cols)\n",
        "print(validation_examples.shape)\n",
        "train_examples = prepare_dataset(train_df, rows, cols)\n",
        "print(train_examples.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSSjvfAEV18A"
      },
      "source": [
        "scalogram_plotter(validation_examples[1,:,:],  True)\n",
        "scalogram_plotter(validation_examples[0,:,:],  True)\n",
        "# train examples\n",
        "scalogram_plotter(train_examples[1,:,:],  True)\n",
        "scalogram_plotter(train_examples[0,:,:],  True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG_Oo-NaNNGz"
      },
      "source": [
        "# plot more random scalograms\n",
        "\n",
        "# plt.figure(figsize= (10,10))\n",
        "# rng = np.random.default_rng(12345)\n",
        "# counter_list = [rng.integers(low=0, high=valid_tensor.shape[0]) for ii in np.arange(2)]\n",
        "\n",
        "# for jj in np.arange(len(counter_list)):\n",
        "#   ax = plt.subplot(2,1, jj + 1)\n",
        "#   scalogram_plotter(valid_tensor[jj,:,:],  True)\n",
        "#   plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q9-VT2vZ58G"
      },
      "source": [
        "validation_labels = valid_groundtruth_df['anomaly'].head(validation_examples.shape[0]).to_numpy()\n",
        "validation_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNlsO_PobR6F"
      },
      "source": [
        "#create validation_labels\n",
        "validation_labels = valid_groundtruth_df['anomaly'].head(rows).to_numpy()\n",
        "validation_labels = prepare_labels(validation_labels[:rows], rows, cols )\n",
        "print(validation_labels.shape)\n",
        "\n",
        "# create train labels\n",
        "train_labels = np.ones([train_examples.shape[0], 1])\n",
        "train_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqnR2NZi3Nm2"
      },
      "source": [
        "# create dataset to serve the model\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_examples, validation_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8q0V8zf4EPu"
      },
      "source": [
        "print(train_dataset)\n",
        "print(validation_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUha8_43Rtqb"
      },
      "source": [
        "# Configure dataset batch size and shuffler\n",
        "BATCH_SIZE = 120\n",
        "# SHUFFLE_BUFFER_SIZE = 100\n",
        "\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "validation_dataset = validation_dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96TWN4_ZSqb1"
      },
      "source": [
        "# Configuring dataset performance\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_I1uaZygyad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beded8cd-3d82-4a99-d694-bda5e0813866"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "num_classes = 1\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                         \n",
        "  tf.keras.layers.InputLayer(input_shape = (64,512,1)),                          \n",
        "  tf.keras.layers.AveragePooling2D(pool_size=(1, 8), strides=(1, 8), padding='valid'),\n",
        "  tf.keras.layers.Conv2D(64, kernel_size=2 , strides=2, activation=tf.keras.layers.LeakyReLU(alpha=0.3)),\n",
        "  tf.keras.layers.Conv2D(128, kernel_size=(2,2), strides=(2,2), activation=tf.keras.layers.LeakyReLU(alpha=0.3)),\n",
        "  tf.keras.layers.Dense(327768,  activation=tf.keras.layers.LeakyReLU(alpha=0.3)),\n",
        "  tf.keras.layers.Dense(300, activation=tf.keras.layers.LeakyReLU(alpha=0.3)),\n",
        "  tf.keras.layers.Dense(327768, activation=tf.keras.layers.LeakyReLU(alpha=0.3)),\n",
        "  tf.keras.layers.Conv2DTranspose(128, kernel_size=1, strides=1, activation=tf.keras.layers.LeakyReLU(alpha=0.3)),\n",
        "  tf.keras.layers.Conv2DTranspose(64, kernel_size=2 , strides=2, activation=tf.keras.layers.LeakyReLU(alpha=0.3)),\n",
        "  tf.keras.layers.Conv2DTranspose(1, kernel_size=2 , strides=2, activation=tf.keras.layers.LeakyReLU(alpha=0.3))\n",
        "\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " average_pooling2d (AverageP  (None, 64, 64, 1)        0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 128)       32896     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16, 16, 327768)    42282072  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16, 16, 300)       98330700  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16, 16, 327768)    98658168  \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 16, 16, 128)      41954432  \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 64)       32832     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 1)        257       \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 281,291,677\n",
            "Trainable params: 281,291,677\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxXou1q5dpNL"
      },
      "source": [
        "# num_classes = 2\n",
        "\n",
        "# model = tf.keras.Sequential([\n",
        "#   tf.keras.layers.Rescaling(1./255),\n",
        "#   tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "#   tf.keras.layers.MaxPooling2D(),\n",
        "#   tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "#   tf.keras.layers.MaxPooling2D(),\n",
        "#   tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "#   tf.keras.layers.MaxPooling2D(),\n",
        "#   tf.keras.layers.Flatten(),\n",
        "#   tf.keras.layers.Dense(128, activation='relu'),\n",
        "#   tf.keras.layers.Dense(num_classes)\n",
        "# ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMLrBXWS5IzU"
      },
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N10tJlL_5NYm"
      },
      "source": [
        "model.fit(\n",
        "  train_dataset,\n",
        "  validation_data=validation_dataset,\n",
        "  epochs=50\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzz1Jk3mMZPi"
      },
      "source": [
        "results = model.evaluate(validation_dataset)\n",
        "print( results)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}